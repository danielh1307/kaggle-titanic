{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer, StandardScaler, MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:22.915500700Z",
     "start_time": "2023-06-07T19:28:22.857098100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build a Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Central methods to call on the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def load_titanic_data():\n",
    "    return pd.read_csv(os.path.join('data', 'train.csv'))\n",
    "\n",
    "def split_data(df):\n",
    "    stratify_by = df[\"Pclass\"]\n",
    "    titanic_train, titanic_test = train_test_split(df, test_size=0.2, stratify=stratify_by, random_state=42)\n",
    "    titanic_train_features = titanic_train.drop('Survived', axis=1)\n",
    "    titanic_train_label = titanic_train['Survived']\n",
    "    titanic_test_features = titanic_test.drop('Survived', axis=1)\n",
    "    titanic_test_label = titanic_test['Survived']\n",
    "    return titanic_train_features, titanic_train_label, titanic_test_features, titanic_test_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:22.918532900Z",
     "start_time": "2023-06-07T19:28:22.875973800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "titanic = load_titanic_data()\n",
    "# we call the train set just \"titanic\"\n",
    "X_train, y_train, X_test, y_test = split_data(titanic)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.085216Z",
     "start_time": "2023-06-07T19:28:22.880006200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze the data\n",
    "\n",
    "See Notebook titanic-kaggle-analyze"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"Age\", \"Embarked\"]\n",
    "    return df.drop(columns_to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.088218Z",
     "start_time": "2023-06-07T19:28:22.898567600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def sex_pipeline():\n",
    "    # we are going to use an OrdinalEncoder to make numerical data of the sex\n",
    "    return Pipeline([\n",
    "        (\"encode\", OrdinalEncoder())\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.126901600Z",
     "start_time": "2023-06-07T19:28:22.903561600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def age_pipeline():\n",
    "    # since there are lots of null values we are going to impute them\n",
    "    return Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\", StandardScaler())\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.129896Z",
     "start_time": "2023-06-07T19:28:22.916501400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def transform_sipsp_parch(df):\n",
    "    # from SibSp and Parch, we create a new column \"Alone\"\n",
    "    # Create a mask for the conditions\n",
    "    mask = (df[\"SibSp\"] == 0) & (df[\"Parch\"] == 0)\n",
    "\n",
    "    # Create a new column, initialized with 1\n",
    "    df.loc[:, \"Alone\"] = 1\n",
    "\n",
    "    df.loc[~mask, \"Alone\"] = 0 # set 0 where the condition is not met\n",
    "    df = df.drop([\"SibSp\", \"Parch\"], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.129896Z",
     "start_time": "2023-06-07T19:28:22.927722200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def transform_sipsp_parch_only_0_1(df):\n",
    "    # from SibSp and Parch, we create a new column \"Alone\"\n",
    "    # Create a mask for the conditions\n",
    "    sibSpMask = (df[\"SibSp\"] == 0)\n",
    "    parchMask = (df[\"Parch\"] == 0)\n",
    "\n",
    "    # Create two new columns, initialized with 1\n",
    "    df.loc[:, \"Wo_SibSp\"] = 1\n",
    "    df.loc[:, \"Wo_Parch\"] = 1\n",
    "\n",
    "    df.loc[~sibSpMask, \"Wo_SibSp\"] = 0 # set 0 where the condition is not met\n",
    "    df.loc[~parchMask, \"Wo_Parch\"] = 0 # set 0 where the condition is not met\n",
    "    df = df.drop([\"SibSp\", \"Parch\"], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.129896Z",
     "start_time": "2023-06-07T19:28:22.939022900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def embarked_pipeline():\n",
    "    # we impute the null values with the most frequent and afterward encode it\n",
    "    return  Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encode\", OrdinalEncoder())\n",
    "    ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.129896Z",
     "start_time": "2023-06-07T19:28:22.950001100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def fare_pipeline():\n",
    "    # we impute the null values with the median\n",
    "    return Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\", StandardScaler())\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.131900Z",
     "start_time": "2023-06-07T19:28:22.962089700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def preprocess_feature(X):\n",
    "    # drop the columns\n",
    "    X = drop_columns(X)\n",
    "\n",
    "    # create column \"Wo_SibSp\" and \"Wo_Parch\" from [\"SibSp\", \"Parch\"]\n",
    "    transformer = FunctionTransformer(transform_sipsp_parch_only_0_1)\n",
    "    #X = transformer.transform(X)\n",
    "\n",
    "    # since we have \"0\" values in Fare, we replace them with \"NaN\" (the imputer in the pipeline will change those afterwards)\n",
    "    X['Fare'] = X['Fare'].replace(0, np.nan)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def apply_pipeline(X, pipeline):\n",
    "    # here we do only a \"transform\", no \"fit\"!\n",
    "    return pd.DataFrame(pipeline.transform(X), columns=pipeline.get_feature_names_out(), index=X.index)\n",
    "\n",
    "\n",
    "transformers = [\n",
    "    ('Sex', sex_pipeline(), ['Sex']),\n",
    "    #('Age', age_pipeline(), ['Age']),\n",
    "    #('Embarked', embarked_pipeline(), ['Embarked']),\n",
    "    ('Fare', fare_pipeline(), ['Fare'])\n",
    "]\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "ct = ColumnTransformer(transformers, remainder=\"passthrough\")\n",
    "\n",
    "# Create the pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"preprocessor\", ct)\n",
    "])\n",
    "\n",
    "X_train = preprocess_feature(X_train)\n",
    "\n",
    "# fit the pipeline on the preprocessed features\n",
    "preprocessing_pipeline.fit(X_train)\n",
    "\n",
    "# apply the pipeline\n",
    "X_train = apply_pipeline(X_train, preprocessing_pipeline)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.131900Z",
     "start_time": "2023-06-07T19:28:22.975024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "     Sex__Sex  Fare__Fare  remainder__Pclass  remainder__SibSp  \\\n820       0.0    1.257206                1.0               1.0   \n439       1.0   -0.454550                2.0               0.0   \n821       1.0   -0.492446                3.0               0.0   \n403       1.0   -0.344214                3.0               1.0   \n343       1.0   -0.402991                2.0               0.0   \n514       1.0   -0.516507                3.0               0.0   \n40        0.0   -0.475689                3.0               1.0   \n101       1.0   -0.508258                3.0               0.0   \n93        1.0   -0.246767                3.0               1.0   \n81        1.0   -0.475173                3.0               0.0   \n\n     remainder__Parch  \n820               1.0  \n439               0.0  \n821               0.0  \n403               0.0  \n343               0.0  \n514               0.0  \n40                0.0  \n101               0.0  \n93                2.0  \n81                0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex__Sex</th>\n      <th>Fare__Fare</th>\n      <th>remainder__Pclass</th>\n      <th>remainder__SibSp</th>\n      <th>remainder__Parch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>820</th>\n      <td>0.0</td>\n      <td>1.257206</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>1.0</td>\n      <td>-0.454550</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>1.0</td>\n      <td>-0.492446</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>1.0</td>\n      <td>-0.344214</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>1.0</td>\n      <td>-0.402991</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>1.0</td>\n      <td>-0.516507</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.0</td>\n      <td>-0.475689</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>1.0</td>\n      <td>-0.508258</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>1.0</td>\n      <td>-0.246767</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>1.0</td>\n      <td>-0.475173</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.132900700Z",
     "start_time": "2023-06-07T19:28:22.996035300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Save the data as train_preprocessed.csv\n",
    "\n",
    "filepath = os.path.join('data', 'train_preprocessed.csv')\n",
    "X_train_preprocessed = pd.DataFrame(X_train)\n",
    "X_train_preprocessed[\"Survived\"] = y_train\n",
    "X_train_preprocessed.to_csv(filepath, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.132900700Z",
     "start_time": "2023-06-07T19:28:23.005353300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess and save the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "     Sex__Sex  Fare__Fare  remainder__Pclass  remainder__SibSp  \\\n132       0.0   -0.372056                3.0               1.0   \n3         0.0    0.424014                1.0               1.0   \n270       1.0   -0.031767                1.0               0.0   \n421       1.0   -0.511609                3.0               0.0   \n154       1.0   -0.520287                3.0               0.0   \n292       1.0   -0.405569                2.0               0.0   \n304       1.0   -0.505078                3.0               0.0   \n202       1.0   -0.537131                3.0               0.0   \n810       1.0   -0.508429                3.0               0.0   \n108       1.0   -0.508258                3.0               0.0   \n\n     remainder__Parch  \n132               0.0  \n3                 0.0  \n270               0.0  \n421               0.0  \n154               0.0  \n292               0.0  \n304               0.0  \n202               0.0  \n810               0.0  \n108               0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex__Sex</th>\n      <th>Fare__Fare</th>\n      <th>remainder__Pclass</th>\n      <th>remainder__SibSp</th>\n      <th>remainder__Parch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>132</th>\n      <td>0.0</td>\n      <td>-0.372056</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.424014</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>1.0</td>\n      <td>-0.031767</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>1.0</td>\n      <td>-0.511609</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>1.0</td>\n      <td>-0.520287</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>1.0</td>\n      <td>-0.405569</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>1.0</td>\n      <td>-0.505078</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>1.0</td>\n      <td>-0.537131</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>1.0</td>\n      <td>-0.508429</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>1.0</td>\n      <td>-0.508258</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the test data\n",
    "X_test = preprocess_feature(X_test)\n",
    "\n",
    "# apply the pipeline\n",
    "X_test = apply_pipeline(X_test, preprocessing_pipeline)\n",
    "\n",
    "X_test.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.132900700Z",
     "start_time": "2023-06-07T19:28:23.019354600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "filepath = os.path.join('data', 'train_test_preprocessed.csv')\n",
    "X_test_preprocessed = pd.DataFrame(X_test)\n",
    "X_test_preprocessed[\"Survived\"] = y_test\n",
    "X_test_preprocessed.to_csv(filepath, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.132900700Z",
     "start_time": "2023-06-07T19:28:23.036715500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and test the model\n",
    "\n",
    "See Notebook titanic-kaggle-train-test.pynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create result for Kaggle\n",
    "\n",
    "Here we preprocess the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def load_titanic_test_data():\n",
    "    return pd.read_csv(os.path.join('data', 'test.csv'))\n",
    "\n",
    "X_final = load_titanic_test_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.132900700Z",
     "start_time": "2023-06-07T19:28:23.049545600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# we need to save the PassengerId\n",
    "x_final_passenger_id = X_final[\"PassengerId\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.133900Z",
     "start_time": "2023-06-07T19:28:23.064114800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "   Sex__Sex  Fare__Fare  remainder__Pclass  remainder__SibSp  \\\n0       1.0   -0.509631                3.0               0.0   \n1       0.0   -0.526732                3.0               1.0   \n2       1.0   -0.471306                2.0               0.0   \n3       1.0   -0.492446                3.0               0.0   \n4       0.0   -0.417685                3.0               1.0   \n5       1.0   -0.480845                3.0               0.0   \n6       0.0   -0.513756                3.0               0.0   \n7       1.0   -0.073014                2.0               1.0   \n8       0.0   -0.522005                3.0               0.0   \n9       1.0   -0.173038                3.0               2.0   \n\n   remainder__Parch  PassengerId  \n0               0.0          892  \n1               0.0          893  \n2               0.0          894  \n3               0.0          895  \n4               1.0          896  \n5               0.0          897  \n6               0.0          898  \n7               1.0          899  \n8               0.0          900  \n9               0.0          901  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex__Sex</th>\n      <th>Fare__Fare</th>\n      <th>remainder__Pclass</th>\n      <th>remainder__SibSp</th>\n      <th>remainder__Parch</th>\n      <th>PassengerId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>-0.509631</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>892</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>-0.526732</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>893</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-0.471306</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>894</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.492446</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>895</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>-0.417685</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>896</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>-0.480845</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>897</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>-0.513756</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>898</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>-0.073014</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>899</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>-0.522005</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>900</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>-0.173038</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>901</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the data\n",
    "X_final = preprocess_feature(X_final)\n",
    "\n",
    "# apply the pipeline\n",
    "X_final = apply_pipeline(X_final, preprocessing_pipeline)\n",
    "\n",
    "X_final[\"PassengerId\"] = x_final_passenger_id\n",
    "\n",
    "X_final.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.133900Z",
     "start_time": "2023-06-07T19:28:23.074216300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "filepath = os.path.join(\"data\", \"test_preprocessed.csv\")\n",
    "X_final.to_csv(filepath, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T19:28:23.239867100Z",
     "start_time": "2023-06-07T19:28:23.095838Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
